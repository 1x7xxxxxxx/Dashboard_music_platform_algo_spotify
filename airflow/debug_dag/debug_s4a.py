"""
üêõ DEBUGGER ULTIME - SPOTIFY FOR ARTISTS (S4A)
Ce script simule l'ex√©cution compl√®te du pipeline S4A sans Airflow.
Il teste :
1. Variables d'environnement (.env)
2. D√©tection des fichiers CSV (Raw Directory)
3. Parsing (Extraction du nom de chanson, Dates, Streams)
4. Connexion BDD
5. Simulation d'insertion SQL (Dry Run)
"""

import os
import sys
import logging
import pandas as pd
from pathlib import Path
from dotenv import load_dotenv
from datetime import datetime

# --- Configuration Logging ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("S4ADebug")

# --- Chargement Environnement ---
load_dotenv()

# Ajout du chemin pour importer vos modules
project_root = Path(__file__).resolve().parent
sys.path.append(str(project_root))

# Imports conditionnels
try:
    from src.database.postgres_handler import PostgresHandler
    from src.transformers.s4a_csv_parser import S4ACSVParser
    MODULES_AVAILABLE = True
except ImportError as e:
    logger.error(f"‚ùå Erreur d'import critique : {e}")
    logger.error("V√©rifiez que vous √™tes √† la racine du projet.")
    MODULES_AVAILABLE = False

# Chemins
RAW_DIR = project_root / "data" / "raw" / "spotify_for_artists"

def print_header(title):
    print(f"\n{'='*60}")
    print(f"üéµ  {title.upper()}")
    print(f"{'='*60}")

def step_1_check_env():
    print_header("√âtape 1 : V√©rification Environnement")
    
    # V√©rif variables BDD
    vars_bdd = ["DATABASE_HOST", "DATABASE_NAME", "DATABASE_USER", "DATABASE_PASSWORD"]
    missing = [v for v in vars_bdd if not os.getenv(v)]
    
    if missing:
        logger.error(f"‚ùå Variables BDD manquantes : {', '.join(missing)}")
        return False
    else:
        logger.info("‚úÖ Variables BDD d√©tect√©es.")

    # V√©rif Dossier
    if not RAW_DIR.exists():
        logger.warning(f"‚ö†Ô∏è Le dossier RAW n'existe pas : {RAW_DIR}")
        try:
            os.makedirs(RAW_DIR, exist_ok=True)
            logger.info("‚úÖ Dossier cr√©√©.")
        except:
            logger.error("‚ùå Impossible de cr√©er le dossier.")
            return False
    else:
        logger.info(f"‚úÖ Dossier RAW pr√©sent : {RAW_DIR}")
    
    return True

def step_2_scan_files():
    print_header("√âtape 2 : Scan des fichiers")
    files = [f for f in os.listdir(RAW_DIR) if f.lower().endswith('.csv')]
    
    if not files:
        logger.warning("‚ö†Ô∏è Aucun fichier CSV trouv√©.")
        logger.info("üí° Action : D√©posez un fichier S4A (ex: 'Mon Titre_20251010.csv') dans 'data/raw/spotify_for_artists'")
        return []
    
    logger.info(f"‚úÖ {len(files)} fichier(s) trouv√©(s) :")
    for f in files:
        print(f"   - {f}")
    
    return files

def step_3_test_parsing(files):
    print_header("√âtape 3 : Test Parsing (S4ACSVParser)")
    parser = S4ACSVParser()
    valid_data = []

    for filename in files:
        file_path = RAW_DIR / filename
        print(f"\nüìÑ Analyse de : {filename}")
        
        # Test extraction nom de fichier
        extracted_name = parser._extract_song_name_from_filename(filename)
        print(f"   üè∑Ô∏è  Nom extrait du fichier : '{extracted_name}'")

        try:
            result = parser.parse_csv_file(file_path)
            
            ftype = result.get('type')
            data = result.get('data')

            if not ftype or not data:
                logger.error(f"   ‚ùå √âchec Parsing : Type non d√©tect√© ou Data vide.")
                logger.error(f"      - Type retourn√©: {ftype}")
                logger.error(f"      - Nb lignes: {len(data) if data else 0}")
                continue

            logger.info(f"   ‚úÖ Type d√©tect√© : {ftype.upper()}")
            logger.info(f"   üìä Lignes extraites : {len(data)}")
            
            # Inspection d'un √©chantillon (Premi√®re et derni√®re ligne)
            if data:
                first = data[0]
                last = data[-1]
                print(f"      üîé Echantillon (Ligne 1) : {first}")
                print(f"      üîé Echantillon (Ligne {len(data)}) : {last}")
                
                # V√©rification de coh√©rence
                if ftype == 'song_timeline' and first.get('song') != extracted_name:
                    logger.warning(f"      ‚ö†Ô∏è Attention : Le nom dans les donn√©es ('{first.get('song')}') diff√®re du nom extrait ('{extracted_name}') ?")

            valid_data.append((ftype, data))
                
        except Exception as e:
            logger.error(f"   ‚ùå Exception Parser : {e}")
            import traceback
            traceback.print_exc()

    return valid_data

def step_4_dry_run_db(parsed_results):
    print_header("√âtape 4 : Test BDD & Simulation Insertion")
    
    if not parsed_results:
        logger.info("‚è© Pas de donn√©es √† ins√©rer. Fin.")
        return

    # Connexion
    try:
        db = PostgresHandler(
            host=os.getenv('DATABASE_HOST'),
            port=int(os.getenv('DATABASE_PORT', 5432)),
            database=os.getenv('DATABASE_NAME'),
            user=os.getenv('DATABASE_USER'),
            password=os.getenv('DATABASE_PASSWORD')
        )
        logger.info("‚úÖ Connexion BDD √©tablie.")
    except Exception as e:
        logger.error(f"‚ùå √âchec connexion BDD : {e}")
        return

    # Simulation par Type de Fichier
    for ftype, data in parsed_results:
        print(f"\nüîπ Simulation pour Type : {ftype.upper()} ({len(data)} lignes)")
        
        if not data: continue
        sample = data[0]

        if ftype == 'song_timeline':
            print(f"   üéØ Table Cible : s4a_song_timeline")
            print(f"   üîë Cl√© d'unicit√© (Conflict) : ['song', 'date']")
            print(f"   üìù Colonnes √† Update : ['streams', 'collected_at']")
            
            print("   üìù Requ√™te SQL simul√©e (Upsert) :")
            print(f"""
            INSERT INTO s4a_song_timeline (song, date, streams)
            VALUES ('{sample['song']}', '{sample['date']}', {sample['streams']})
            ON CONFLICT (song, date) DO UPDATE 
            SET streams = EXCLUDED.streams, collected_at = NOW();
            """)
            
        elif ftype == 'audience':
            print(f"   üéØ Table Cible : s4a_audience")
            print(f"   üîë Cl√© d'unicit√© (Conflict) : ['date']")
            print("   üìù Requ√™te SQL simul√©e :")
            print(f"""
            INSERT INTO s4a_audience (date, listeners, streams, followers)
            VALUES ('{sample.get('date')}', ...)
            ON CONFLICT (date) DO UPDATE ...
            """)
            
        elif ftype == 'songs_global':
             print(f"   üéØ Table Cible : s4a_songs_global")
             print(f"   üîë Cl√© d'unicit√© (Conflict) : ['song']")
             print("   üìù Requ√™te SQL simul√©e :")
             print(f"""
             INSERT INTO s4a_songs_global (song, listeners, ...)
             VALUES ('{sample.get('song')}', ...)
             ON CONFLICT (song) DO UPDATE ...
             """)

    db.close()

if __name__ == "__main__":
    if not MODULES_AVAILABLE:
        sys.exit(1)
        
    if step_1_check_env():
        files = step_2_scan_files()
        if files:
            results = step_3_test_parsing(files)
            step_4_dry_run_db(results)
    
    print("\n‚úÖ Debugging termin√©.")