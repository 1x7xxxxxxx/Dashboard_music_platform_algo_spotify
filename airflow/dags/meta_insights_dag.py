from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import sys
import os
from pathlib import Path

# 1. Ajout du chemin racine pour trouver les modules src.*
# On remonte de 2 niveaux (src/dags/ -> src/ -> root)
project_root = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(project_root))

# 2. Import du Watcher que nous avons crÃ©Ã©
from src.collectors.meta_insight_watcher import MetaAdsWatcher

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 0,
    'retry_delay': timedelta(minutes=5),
}

# 3. DÃ©finition du DAG
with DAG(
    'meta_insights_watcher',  # C'est cet ID qu'Airflow cherchait !
    default_args=default_args,
    description='Surveille et importe les CSV Insights Meta Ads (Age, Pays, etc.)',
    schedule_interval=None,   # DÃ©clenchement manuel via Streamlit
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['meta', 'csv', 'insights']
) as dag:

    def run_watcher_task():
        print("ðŸš€ DÃ©marrage du Meta Ads Insight Watcher...")
        watcher = MetaAdsWatcher()
        watcher.process_files()
        print("âœ… Fin du traitement.")

    t1 = PythonOperator(
        task_id='process_meta_insights_files',
        python_callable=run_watcher_task,
    )   