version: '3.8'

services:
  # ============================================================================
  # POSTGRESQL - Base de données unique
  # ============================================================================
  postgres:
    image: postgres:17
    container_name: postgres_spotify_airflow
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
      POSTGRES_DB: airflow_db
    ports:
      - '5433:5432'
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init_db.sql:/docker-entrypoint-initdb.d/init_db.sql
    healthcheck:
      test: ['CMD', 'pg_isready', '-U', 'postgres']
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - airflow_network

  # ============================================================================
  # AIRFLOW INIT - Initialisation
  # ============================================================================
  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      postgres:
        condition: service_healthy
    environment: &airflow-common-env
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:Wowow1357911!@postgres:5432/airflow_db
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.basic_auth
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: 1x7xxxxxxx
      _AIRFLOW_WWW_USER_PASSWORD: Wowow1357911!
      PYTHONPATH: /opt/airflow
      
      # Database pour les DAGs (spotify_etl)
      DATABASE_HOST: postgres
      DATABASE_PORT: 5432
      DATABASE_NAME: spotify_etl
      DATABASE_USER: postgres
      DATABASE_PASSWORD: Wowow1357911!
      
      # Spotify API
      SPOTIFY_CLIENT_ID: ${SPOTIFY_CLIENT_ID}
      SPOTIFY_CLIENT_SECRET: ${SPOTIFY_CLIENT_SECRET}
      SPOTIFY_ARTIST_IDS: 7sbfafbLjNZGZJZjZ3xoPB
      
      # Meta Ads
      META_APP_ID: ${META_APP_ID}
      META_APP_SECRET: ${META_APP_SECRET}
      META_ACCESS_TOKEN: ${META_ACCESS_TOKEN}
      META_AD_ACCOUNT_ID: act_567214713853881
      META_API_VERSION: v21.0
      
      # YouTube API
      YOUTUBE_API_KEY: ${YOUTUBE_API_KEY}
      YOUTUBE_CHANNEL_ID: ${YOUTUBE_CHANNEL_ID}
      
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./.env:/opt/airflow/.env
    command: version
    networks:
      - airflow_network

  # ============================================================================
  # AIRFLOW WEBSERVER
  # ============================================================================
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_webserver
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      <<: *airflow-common-env
    ports:
      - '8080:8080'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./.env:/opt/airflow/.env
    command: webserver
    healthcheck:
      test: ['CMD', 'curl', '--fail', 'http://localhost:8080/health']
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    networks:
      - airflow_network

  # ============================================================================
  # AIRFLOW SCHEDULER
  # ============================================================================
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow_scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      <<: *airflow-common-env
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./.env:/opt/airflow/.env
    command: scheduler
    restart: unless-stopped
    networks:
      - airflow_network

# ============================================================================
# VOLUMES
# ============================================================================
volumes:
  postgres_data:

# ============================================================================
# NETWORKS
# ============================================================================
networks:
  airflow_network:
    driver: bridge